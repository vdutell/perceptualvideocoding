{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on State of the Art Compression Schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this Document?\n",
    "As I research this project there is HEAPS to learn about the state of the art compression schemes already in use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Main Players\n",
    "\n",
    "**HEVC/H.265/MPEG-H_2** High Efficiency Video Coding is the most recent generation of AVC/H.264. This is a patented compression scheme developed by the Joint Collaborative Team on Video Coding (JCT-VC) as part of ISO/IEC MPEG and ITU-T VCEG. It was released in 2013, and extended for 3D and for Screen Captured Content (SCC) after. The organizations that participated in JCT-VC own many patents used in the coding scheme, and therefore the scheme is propriatery, and fees are charged to those implementing the scheme.  \n",
    "\n",
    "**AV1** AOMedia Video 1 is main competitor to HEVC, and is open source. It is currently in development by the Alliance for Open Media (AOMedia), a consortium of large players in the video content market. It is meant to replace VP9, the previous major open source video coder. It is in the late stages of development, slated to have a bistream freeze (be finalized) in late 2017. It is approximately on par with HVEC in terms of compression rate and quality.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEVC - Main Pipeline Components\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AV1 - Main Pipeline Components\n",
    "\n",
    "### Non-Binary Entropy Coding\n",
    "Instead of using binary bits (1 or 0) to encode, uses hexadecimal (16-symbols) system. You pack 4x more information into each symbol, but per-symbol overheads make it less than 4x more expensive.\n",
    "\n",
    "### Adaptive Entropy Coding\n",
    "I don't really understand. Something about probabilities of a given pixel adapted to these hex symbols, and the probabilities for the symbols can change based on the movie type?: [https://people.xiph.org/~tterribe/pubs/lca2017/aom.pdf](https://people.xiph.org/~tterribe/pubs/lca2017/aom.pdf) \n",
    "\n",
    "### Adaptive De-Ringing\n",
    "Predicesor VP9 had rinding artifacts. Estimate orientation of a given block, smooth strongly parallel to the block and smooth weakly perpendicular to block.\n",
    "\n",
    "### Perceptutal Vector Quantization \n",
    "Instead of computing displacement between frames and calculating scalar quantization, uses householder reflections on a hypsersphere, with a predicted and true input taking positions on this sphere, and (calcuting the difference between a prediction and the true input?)\n",
    "\n",
    "### Rate-Distortion Modeling - PSNR-HVS\n",
    "Estimate for a given frame how many bits we'll use, as well as how distorted the signal will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
